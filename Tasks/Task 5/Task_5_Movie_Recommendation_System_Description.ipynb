{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Download and Load MovieLens 100K Dataset"
      ],
      "metadata": {
        "id": "HttYYpZJt2Tg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUSDQYk7qgkC",
        "outputId": "636e683a-156e-4427-f48f-6464eb48c692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/prajitdatta/movielens-100k-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.77M/4.77M [00:01<00:00, 4.90MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Dataset path: /root/.cache/kagglehub/datasets/prajitdatta/movielens-100k-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Download MovieLens 100K Dataset from KaggleHub\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"prajitdatta/movielens-100k-dataset\")\n",
        "print(\"üìÇ Dataset path:\", path)\n",
        "\n",
        "# Dataset files are in this subfolder\n",
        "base_path = path + \"/ml-100k\"\n",
        "ratings_path = base_path + \"/u.data\"\n",
        "movies_path = base_path + \"/u.item\"\n",
        "\n",
        "# Load data\n",
        "ratings = pd.read_csv(ratings_path, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
        "movies = pd.read_csv(movies_path, sep=\"|\", encoding=\"latin-1\", header=None, usecols=[0, 1], names=[\"item_id\", \"title\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create User-Item Matrix"
      ],
      "metadata": {
        "id": "47NM_fLZt5LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create User-Item Matrix\n",
        "user_item_matrix = ratings.pivot_table(index=\"user_id\", columns=\"item_id\", values=\"rating\")\n",
        "user_item_matrix.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "cXN5oHKZqree"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Split Ratings Data into Train and Test Sets (User-wise)"
      ],
      "metadata": {
        "id": "6GSRY9xtt9YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split Data into Train and Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# We'll simulate a test split by hiding 20% of each user's ratings\n",
        "def train_test_split_userwise(df, test_size=0.2):\n",
        "    train_list = []\n",
        "    test_list = []\n",
        "    for user in df[\"user_id\"].unique():\n",
        "        user_data = df[df[\"user_id\"] == user]\n",
        "        if len(user_data) >= 5:\n",
        "            train, test = train_test_split(user_data, test_size=test_size, random_state=42)\n",
        "            train_list.append(train)\n",
        "            test_list.append(test)\n",
        "        else:\n",
        "            train_list.append(user_data)\n",
        "    return pd.concat(train_list), pd.concat(test_list)\n",
        "\n",
        "ratings_train, ratings_test = train_test_split_userwise(ratings)\n"
      ],
      "metadata": {
        "id": "15p5XeOequr-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Define Movie Recommendation Function (User-Based Filtering)"
      ],
      "metadata": {
        "id": "77zaWUZRuCSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Recommendation Function\n",
        "def recommend_movies(user_id, k=5):\n",
        "    if user_id not in user_item_matrix.index:\n",
        "        return []\n",
        "\n",
        "    user_vector = user_item_matrix.loc[[user_id]]\n",
        "    similarities = cosine_similarity(user_vector, user_item_matrix)[0]\n",
        "\n",
        "    # Filter weak similarities\n",
        "    similarity_threshold = 0.1\n",
        "    similarities[similarities < similarity_threshold] = 0\n",
        "\n",
        "    weighted_ratings = np.dot(similarities, user_item_matrix.values)\n",
        "    sim_sum = np.array([similarities.sum()] * user_item_matrix.shape[1])\n",
        "    scores = weighted_ratings / np.where(sim_sum == 0, 1e-8, sim_sum)\n",
        "\n",
        "    # Exclude movies the user has already rated\n",
        "    user_rated_items = set(user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index)\n",
        "    unseen_items = [i for i in user_item_matrix.columns if i not in user_rated_items]\n",
        "\n",
        "    movie_scores = [(item, scores[idx]) for idx, item in enumerate(user_item_matrix.columns) if item in unseen_items]\n",
        "    top_k = sorted(movie_scores, key=lambda x: x[1], reverse=True)[:k]\n",
        "\n",
        "    return [movies[movies[\"item_id\"] == item][\"title\"].values[0] for item, _ in top_k]\n"
      ],
      "metadata": {
        "id": "qxA-nFEMqxS8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Evaluate the Model using Precision@K"
      ],
      "metadata": {
        "id": "A8usZz-FuGo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Evaluate Precision@K\n",
        "def precision_at_k(actual, predicted, k):\n",
        "    if len(predicted) > k:\n",
        "        predicted = predicted[:k]\n",
        "    return len(set(predicted) & set(actual)) / k\n",
        "\n",
        "# Choose test users with enough test ratings\n",
        "min_ratings = 5\n",
        "user_rating_counts = ratings_test[\"user_id\"].value_counts()\n",
        "eligible_users = user_rating_counts[user_rating_counts >= min_ratings].index.tolist()\n",
        "test_users = np.random.choice(eligible_users, size=min(100, len(eligible_users)), replace=False)\n",
        "\n",
        "k = 5\n",
        "precisions = []\n",
        "\n",
        "for user_id in test_users:\n",
        "    actual_movies = ratings_test[ratings_test[\"user_id\"] == user_id][\"item_id\"].tolist()\n",
        "    recommended_titles = recommend_movies(user_id, k=k)\n",
        "\n",
        "    # Convert actual item_ids to titles\n",
        "    actual_titles = movies[movies[\"item_id\"].isin(actual_movies)][\"title\"].tolist()\n",
        "\n",
        "    prec = precision_at_k(actual_titles, recommended_titles, k)\n",
        "    precisions.append(prec)\n",
        "\n",
        "print(f\"üìà Average Precision@{k}: {np.mean(precisions):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvF1_u2Iqzxz",
        "outputId": "863fea6d-dc50-421a-bdb2-99088e269d05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Average Precision@5: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Try Recommendations for a Sample User"
      ],
      "metadata": {
        "id": "zHkcv1fnuLrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Try it for one user\n",
        "sample_user = test_users[0]\n",
        "print(f\"üîç Recommendations for User {sample_user}:\")\n",
        "for title in recommend_movies(sample_user):\n",
        "    print(\"‚úîÔ∏è\", title)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYzmzZsHq4MY",
        "outputId": "7d93e9c1-ca46-4dfa-ef1a-e69c91368c72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Recommendations for User 783:\n",
            "‚úîÔ∏è Titanic (1997)\n",
            "‚úîÔ∏è L.A. Confidential (1997)\n",
            "‚úîÔ∏è Saint, The (1997)\n",
            "‚úîÔ∏è Good Will Hunting (1997)\n",
            "‚úîÔ∏è Star Wars (1977)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Build Streamlit App Interface for Recommendations"
      ],
      "metadata": {
        "id": "rxs3dLvMuPbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile movie_recommender_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "st.set_page_config(page_title=\"üé¨ Movie Recommender\", layout=\"centered\")\n",
        "\n",
        "st.title(\"üé• Movie Recommendation System\")\n",
        "st.markdown(\"Recommend movies to a user based on user similarity (Collaborative Filtering).\")\n",
        "\n",
        "# üì¶ Download MovieLens 100K dataset\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    path = kagglehub.dataset_download(\"prajitdatta/movielens-100k-dataset\")\n",
        "    base_path = path + \"/ml-100k\"\n",
        "    ratings_path = base_path + \"/u.data\"\n",
        "    movies_path = base_path + \"/u.item\"\n",
        "\n",
        "    ratings = pd.read_csv(ratings_path, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
        "    movies = pd.read_csv(movies_path, sep=\"|\", encoding=\"latin-1\", header=None, usecols=[0, 1], names=[\"item_id\", \"title\"])\n",
        "    return ratings, movies\n",
        "\n",
        "ratings, movies = load_data()\n",
        "\n",
        "# üìä Create User-Item Matrix\n",
        "user_item_matrix = ratings.pivot_table(index=\"user_id\", columns=\"item_id\", values=\"rating\").fillna(0)\n",
        "\n",
        "# üîç Recommendation Function\n",
        "def recommend_movies(user_id, k=5):\n",
        "    if user_id not in user_item_matrix.index:\n",
        "        return []\n",
        "\n",
        "    user_vector = user_item_matrix.loc[[user_id]]\n",
        "    similarities = cosine_similarity(user_vector, user_item_matrix)[0]\n",
        "\n",
        "    # Filter weak similarities\n",
        "    similarity_threshold = 0.1\n",
        "    similarities[similarities < similarity_threshold] = 0\n",
        "\n",
        "    weighted_ratings = np.dot(similarities, user_item_matrix.values)\n",
        "    sim_sum = np.array([similarities.sum()] * user_item_matrix.shape[1])\n",
        "    scores = weighted_ratings / np.where(sim_sum == 0, 1e-8, sim_sum)\n",
        "\n",
        "    user_rated_items = set(user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index)\n",
        "    unseen_items = [i for i in user_item_matrix.columns if i not in user_rated_items]\n",
        "\n",
        "    movie_scores = [(item, scores[idx]) for idx, item in enumerate(user_item_matrix.columns) if item in unseen_items]\n",
        "    top_k = sorted(movie_scores, key=lambda x: x[1], reverse=True)[:k]\n",
        "\n",
        "    return [movies[movies[\"item_id\"] == item][\"title\"].values[0] for item, _ in top_k]\n",
        "\n",
        "# üéõÔ∏è User Input\n",
        "user_ids = sorted(ratings[\"user_id\"].unique())\n",
        "selected_user = st.selectbox(\"Select a User ID:\", user_ids)\n",
        "top_k = st.slider(\"How many movies to recommend?\", 1, 20, 5)\n",
        "\n",
        "# üé¨ Show Recommendations\n",
        "if st.button(\"Get Recommendations\"):\n",
        "    recommendations = recommend_movies(selected_user, k=top_k)\n",
        "    if recommendations:\n",
        "        st.success(\"Top Recommended Movies:\")\n",
        "        for idx, title in enumerate(recommendations, start=1):\n",
        "            st.write(f\"{idx}. {title}\")\n",
        "    else:\n",
        "        st.warning(\"No recommendations available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6yUKHrXrx4l",
        "outputId": "545baac9-f20a-480a-e98e-6185705eba8a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing movie_recommender_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Install Dependencies and Authenticate Ngrok"
      ],
      "metadata": {
        "id": "1KQgLE4tuTUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q streamlit kagglehub pyngrok\n",
        "\n",
        "# Authenticate with your Ngrok token (replace with your real token!)\n",
        "!ngrok config add-authtoken YOUR_TOKEN_HERE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42Y9y95usfWn",
        "outputId": "11cd33ce-cd06-4b9a-d0c0-75fed270b727"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Launch Streamlit App with Ngrok Tunnel"
      ],
      "metadata": {
        "id": "0pdvjSHsuYmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch Streamlit app in background\n",
        "!streamlit run movie_recommender_app.py &>/content/logs.txt &\n",
        "\n",
        "# Create a tunnel using options dictionary (recommended for latest ngrok)\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()  # Kill previous tunnels\n",
        "public_url = ngrok.connect(addr=8501, proto=\"http\")  # Specify addr explicitly\n",
        "print(\"üåç App is live at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1NOfohJr02b",
        "outputId": "833495b8-1468-4062-e1c1-1393f2e1119b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåç App is live at: NgrokTunnel: \"https://b481305b25b1.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}